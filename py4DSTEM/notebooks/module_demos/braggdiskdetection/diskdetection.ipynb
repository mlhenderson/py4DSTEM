{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module: braggdiskdetection\n",
    "\n",
    "This module contains functions finding the positions of the Bragg disks in a 4DSTEM scan.  Generally this will involve two steps: getting a vacuum probe, then finding the Bragg disks using the vacuum probe as a template. \n",
    "\n",
    "## Submodule: diskdetection\n",
    "\n",
    "The notebook demos functions related to finding the Bragg disks.  Using a vacuum probe as a template - i.e. a convolution kernel - a cross correlation (or phase or hybrid correlation) is taken between each DP and the template, and the positions and intensities of all local corraltion maxima are used to identify the Bragg disks.  Erroneous peaks are filtered out with several types of threshold.  Detected Bragg disks are generally stored in PointLists (when run on only selected DPs) or PointListArrays (when run on a full DataCube).\n",
    "\n",
    "This notebook demos:\n",
    "* Disk detection on single or selected diffraction patterns\n",
    "* Disk detection on all diffraction patterns\n",
    "* Additional filtering of detected Bragg disks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages, load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py4DSTEM\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from py4DSTEM.process.braggdiskdetection import find_Bragg_disks_single_DP\n",
    "from py4DSTEM.process.braggdiskdetection import find_Bragg_disks_selected\n",
    "from py4DSTEM.process.braggdiskdetection import find_Bragg_disks\n",
    "from py4DSTEM.process.braggdiskdetection import threshold_Braggpeaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import ipyparallel as ipp\n",
    "\n",
    "from py4DSTEM.process.braggdiskdetection import find_Bragg_disks_single_DP_FK\n",
    "from py4DSTEM.process.braggdiskdetection import PointListArray\n",
    "from py4DSTEM.process.braggdiskdetection import print_progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "#fp = \"/home/ben/Data/20180905_FePO4_unlithiated/raw/Stack1_57x47+30nmss_spot 8_0p05s_CL=600_alpha=0p48_300kV_bin4.dm4\"\n",
    "#fp = \"/Users/Ben/Work/NCEM/Projects/py4DSTEM/sample_data/20180905_FePO4_unlithiated/Stack2_60x60+30nmss_spot 8_0p05s_CL=600_alpha=0p48_300kV_bin4.dm3\"\n",
    "\n",
    "fp = \"/global/u2/m/mhenders/ncem/Stack2_60x60+30nmss_spot 8_0p05s_CL=600_alpha=0p48_300kV_bin4.h5\"\n",
    "dc = py4DSTEM.file.readwrite.read(fp)\n",
    "dc.set_scan_shape(47,57)\n",
    "dc.data4D = np.roll(dc.data4D,-2,1) # Correct for acquisition wrap-around error\n",
    "\n",
    "# Load the template\n",
    "#fp_probetemplate = \"/home/ben/Data/20180905_FePO4_unlithiated/processing/vacuum_probe_kernel.h5\"\n",
    "#fp = \"/Users/Ben/Work/NCEM/Projects/py4DSTEM/sample_data/20180905_FePO4_unlithiated/processing/vacuum_probe_kernel.h5\"\n",
    "fp_probetemplate = \"/global/u2/m/mhenders/ncem/vacuum_probe_kernel.h5\"\n",
    "browser = py4DSTEM.file.readwrite.FileBrowser(fp_probetemplate, rawdatacube=dc)\n",
    "browser.show_dataobjects()\n",
    "probe_kernel = browser.get_dataobject(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a DP\n",
    "\n",
    "Rx=20\n",
    "Ry=25\n",
    "power=0.3\n",
    "\n",
    "DP = dc.data4D[Rx,Ry,:,:]\n",
    "\n",
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(12,12))\n",
    "ax1.matshow(np.average(dc.data4D,axis=(2,3)))\n",
    "ax1.scatter(Ry,Rx,color='r')\n",
    "ax2.matshow(DP**power)\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get peaks\n",
    "\n",
    "corrPower = 0.9\n",
    "sigma = 2\n",
    "edgeBoundary = 20\n",
    "maxNumPeaks = 70\n",
    "minPeakSpacing = 30\n",
    "minRelativeIntensity = 0.005\n",
    "\n",
    "peaks = find_Bragg_disks_single_DP(DP, probe_kernel.data2D,\n",
    "                                   corrPower=corrPower,\n",
    "                                   sigma=sigma,\n",
    "                                   edgeBoundary=edgeBoundary,\n",
    "                                   minRelativeIntensity=minRelativeIntensity,\n",
    "                                   minPeakSpacing=minPeakSpacing,\n",
    "                                   maxNumPeaks=maxNumPeaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show\n",
    "\n",
    "power=0.3\n",
    "size_scale_factor = 500       # Set to zero to make all points the same size\n",
    "\n",
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(12,12))\n",
    "ax1.matshow(np.average(dc.data4D,axis=(2,3)))\n",
    "ax1.scatter(Ry,Rx,color='r')\n",
    "ax2.matshow(DP**power)\n",
    "ax2.scatter(peaks.data['qy'],peaks.data['qx'],color='r',s=size_scale_factor*peaks.data['intensity']/np.max(peaks.data['intensity']))\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Several DPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few DPs\n",
    "\n",
    "Rxs=(20,31,18)\n",
    "Rys=(25,31,10)\n",
    "power=0.3\n",
    "\n",
    "fig,((ax11,ax12),(ax21,ax22))=plt.subplots(2,2,figsize=(12,12))\n",
    "ax11.matshow(np.average(dc.data4D,axis=(2,3)))\n",
    "ax11.scatter(Rys,Rxs,color=('r','yellow','deepskyblue'))\n",
    "ax12.matshow(dc.data4D[Rxs[0],Rys[0],:,:]**power)\n",
    "ax21.matshow(dc.data4D[Rxs[1],Rys[1],:,:]**power)\n",
    "ax22.matshow(dc.data4D[Rxs[2],Rys[2],:,:]**power)\n",
    "\n",
    "ax11.axis('off')\n",
    "ax12.axis('off')\n",
    "ax21.axis('off')\n",
    "ax22.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get peaks\n",
    "\n",
    "corrPower = 0.8\n",
    "sigma = 2\n",
    "edgeBoundary = 20\n",
    "maxNumPeaks = 70\n",
    "minPeakSpacing = 50\n",
    "minRelativeIntensity = 0.001\n",
    "\n",
    "peaks = find_Bragg_disks_selected(dc, probe_kernel.data2D, Rxs, Rys,\n",
    "                                  corrPower=corrPower,\n",
    "                                  sigma=sigma,\n",
    "                                  edgeBoundary=edgeBoundary,\n",
    "                                  minRelativeIntensity=minRelativeIntensity,\n",
    "                                  minPeakSpacing=minPeakSpacing,\n",
    "                                  maxNumPeaks=maxNumPeaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show\n",
    "\n",
    "power=0.3\n",
    "size_scale_factor = 500       # Set to zero to make all points the same size\n",
    "\n",
    "fig,((ax11,ax12),(ax21,ax22))=plt.subplots(2,2,figsize=(12,12))\n",
    "ax11.matshow(np.average(dc.data4D,axis=(2,3)))\n",
    "ax11.scatter(Rys,Rxs,color=('r','g','b'))\n",
    "ax12.matshow(dc.data4D[Rxs[0],Rys[0],:,:]**power)\n",
    "ax21.matshow(dc.data4D[Rxs[1],Rys[1],:,:]**power)\n",
    "ax22.matshow(dc.data4D[Rxs[2],Rys[2],:,:]**power)\n",
    "\n",
    "if size_scale_factor == 0:\n",
    "    ax12.scatter(peaks[0].data['qy'],peaks[0].data['qx'],color='r')\n",
    "    ax21.scatter(peaks[1].data['qy'],peaks[1].data['qx'],color='g')\n",
    "    ax22.scatter(peaks[2].data['qy'],peaks[2].data['qx'],color='b')\n",
    "else:\n",
    "    ax12.scatter(peaks[0].data['qy'],peaks[0].data['qx'],color='r',s=size_scale_factor*peaks[0].data['intensity']/np.max(peaks[0].data['intensity']))\n",
    "    ax21.scatter(peaks[1].data['qy'],peaks[1].data['qx'],color='g',s=size_scale_factor*peaks[1].data['intensity']/np.max(peaks[1].data['intensity']))\n",
    "    ax22.scatter(peaks[2].data['qy'],peaks[2].data['qx'],color='b',s=size_scale_factor*peaks[2].data['intensity']/np.max(peaks[2].data['intensity']))\n",
    "\n",
    "\n",
    "ax11.axis('off')\n",
    "ax12.axis('off')\n",
    "ax21.axis('off')\n",
    "ax22.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ipp.require(\n",
    "    'numpy', \n",
    "    'scipy.ndimage.filters',\n",
    "    'py4DSTEM.file.datastructure', \n",
    "    'py4DSTEM.process.utils'\n",
    "    )\n",
    "def _find_Bragg_disks_single_DP_FK(DP, probe_kernel_FT,\n",
    "                                  corrPower = 1,\n",
    "                                  sigma = 2,\n",
    "                                  edgeBoundary = 20,\n",
    "                                  minRelativeIntensity = 0.005,\n",
    "                                  minPeakSpacing = 60,\n",
    "                                  maxNumPeaks = 70,\n",
    "                                  return_cc = False,\n",
    "                                  peaks = None):\n",
    "    \"\"\"\n",
    "    Finds the Bragg disks in DP by cross, hybrid, or phase correlation with probe_kernel_FT.\n",
    "\n",
    "    After taking the cross/hybrid/phase correlation, a gaussian smoothing is applied\n",
    "    with standard deviation sigma, and all local maxima are found. Detected peaks within\n",
    "    edgeBoundary pixels of the diffraction plane edges are then discarded. Next, peaks with\n",
    "    intensities less than minRelativeIntensity of the brightest peak in the correaltion are\n",
    "    discarded. Then peaks which are within a distance of minPeakSpacing of their nearest neighbor\n",
    "    peak are found, and in each such pair the peak with the lesser correlation intensities is\n",
    "    removed. Finally, if the number of peaks remaining exceeds maxNumPeaks, only the maxNumPeaks\n",
    "    peaks with the highest correlation intensity are retained.\n",
    "\n",
    "    IMPORTANT NOTE: the argument probe_kernel_FT is related to the probe kernels generated by\n",
    "    functions like get_probe_kernel() by:\n",
    "\n",
    "            probe_kernel_FT = np.conj(np.fft.fft2(probe_kernel))\n",
    "\n",
    "    if this function is simply passed a probe kernel, the results will not be meaningful! To run\n",
    "    on a single DP while passing the real space probe kernel as an argument, use\n",
    "    find_Bragg_disks_single_DP().\n",
    "\n",
    "    Accepts:\n",
    "        DP                   (ndarray) a diffraction pattern\n",
    "        probe_kernel_FT      (ndarray) the vacuum probe template, in Fourier space. Related to the\n",
    "                             real space probe kernel by probe_kernel_FT = F(probe_kernel)*, where F\n",
    "                             indicates a Fourier Transform and * indicates complex conjugation.\n",
    "        corrPower            (float between 0 and 1, inclusive) the cross correlation power. A\n",
    "                             value of 1 corresponds to a cross correaltion, and 0 corresponds to a\n",
    "                             phase correlation, with intermediate values giving various hybrids.\n",
    "        sigma                (float) the standard deviation for the gaussian smoothing applied to\n",
    "                             the cross correlation\n",
    "        edgeBoundary         (int) minimum acceptable distance from the DP edge, in pixels\n",
    "        minRelativeIntensity (float) the minimum acceptable correlation peak intensity, relative to\n",
    "                             the intensity of the brightest peak\n",
    "        minPeakSpacing       (float) the minimum acceptable spacing between detected peaks\n",
    "        maxNumPeaks          (int) the maximum number of peaks to return\n",
    "        return_cc            (bool) if True, return the cross correlation\n",
    "        peaks                (PointList) For internal use.\n",
    "                             If peaks is None, the PointList of peak positions is created here.\n",
    "                             If peaks is not None, it is the PointList that detected peaks are added\n",
    "                             to, and must have the appropriate coords ('qx','qy','intensity').\n",
    "\n",
    "    Returns:\n",
    "        peaks                (PointList) the Bragg peak positions and correlation intensities\n",
    "    \"\"\"\n",
    "    # Get cross correlation\n",
    "    cc = py4DSTEM.process.utils.get_cross_correlation_fk(DP, probe_kernel_FT, corrPower)\n",
    "    cc = numpy.maximum(cc,0)\n",
    "    cc = scipy.ndimage.filters.gaussian_filter(cc, sigma)\n",
    "\n",
    "    # Get maxima\n",
    "    maxima_x,maxima_y = py4DSTEM.process.utils.get_maxima_2D(\n",
    "        cc, sigma=sigma, edgeBoundary=edgeBoundary,\n",
    "        minRelativeIntensity=minRelativeIntensity,\n",
    "        minSpacing=minPeakSpacing, maxNumPeaks=maxNumPeaks)\n",
    "\n",
    "    # Make peaks PointList\n",
    "    if peaks is None:\n",
    "        coords = [('qx',float),('qy',float),('intensity',float)]\n",
    "        peaks = py4DSTEM.file.datastructure.PointList(coordinates=coords)\n",
    "    else:\n",
    "        assert(isinstance(peaks,py4DSTEM.file.datastructure.PointList))\n",
    "    peaks.add_tuple_of_nparrays((maxima_x,maxima_y,cc[maxima_x,maxima_y]))\n",
    "\n",
    "    if return_cc:\n",
    "        return peaks, cc\n",
    "    else:\n",
    "        return peaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_Bragg_disks(datacube, probe,\n",
    "                     corrPower = 1,\n",
    "                     sigma = 2,\n",
    "                     edgeBoundary = 20,\n",
    "                     minRelativeIntensity = 0.005,\n",
    "                     minPeakSpacing = 60,\n",
    "                     maxNumPeaks = 70,\n",
    "                     verbose = False,\n",
    "                     view = None):\n",
    "    \"\"\"\n",
    "    Finds the Bragg disks in all diffraction patterns of datacube by cross, hybrid, or phase\n",
    "    correlation with probe.\n",
    "\n",
    "    Accepts:\n",
    "        DP                   (ndarray) a diffraction pattern\n",
    "        probe                (ndarray) the vacuum probe template, in real space.\n",
    "        corrPower            (float between 0 and 1, inclusive) the cross correlation power. A\n",
    "                             value of 1 corresponds to a cross correaltion, and 0 corresponds to a\n",
    "                             phase correlation, with intermediate values giving various hybrids.\n",
    "        sigma                (float) the standard deviation for the gaussian smoothing applied to\n",
    "                             the cross correlation\n",
    "        edgeBoundary         (int) minimum acceptable distance from the DP edge, in pixels\n",
    "        minRelativeIntensity (float) the minimum acceptable correlation peak intensity, relative to\n",
    "                             the intensity of the brightest peak\n",
    "        minPeakSpacing       (float) the minimum acceptable spacing between detected peaks\n",
    "        maxNumPeaks          (int) the maximum number of peaks to return\n",
    "        verbose              (bool) if True, prints completion updates\n",
    "\n",
    "    Returns:\n",
    "        peaks                (PointListArray) the Bragg peak positions and correlation intensities\n",
    "    \"\"\"\n",
    "    # Make the peaks PointListArray\n",
    "    coords = [('qx',float),('qy',float),('intensity',float)]\n",
    "    peaks = PointListArray(coordinates=coords, shape=(datacube.R_Nx, datacube.R_Ny))\n",
    "\n",
    "    # Get the probe kernel FT\n",
    "    probe_kernel_FT = np.conj(np.fft.fft2(probe))\n",
    "\n",
    "    if view is None:\n",
    "        # Loop over all diffraction patterns\n",
    "        t0 = time()\n",
    "        for Rx in range(datacube.R_Nx):\n",
    "            for Ry in range(datacube.R_Ny):\n",
    "                if verbose:\n",
    "                    print_progress_bar(Rx*datacube.R_Ny+Ry+1, datacube.R_Nx*datacube.R_Ny,\n",
    "                                       prefix='Analyzing:', suffix='Complete', length=50)\n",
    "                DP = datacube.data4D[Rx,Ry,:,:]\n",
    "                _find_Bragg_disks_single_DP_FK(DP, probe_kernel_FT,\n",
    "                                              corrPower = corrPower,\n",
    "                                              sigma = sigma,\n",
    "                                              edgeBoundary = edgeBoundary,\n",
    "                                              minRelativeIntensity = minRelativeIntensity,\n",
    "                                              minPeakSpacing = minPeakSpacing,\n",
    "                                              maxNumPeaks = maxNumPeaks,\n",
    "                                              peaks = peaks.get_pointlist(Rx,Ry))\n",
    "        t = time()-t0\n",
    "        print(\"Analyzed {} diffraction patterns in {}h {}m {}s\".format(datacube.R_N, int(t/3600),\n",
    "                                                                       int(t/60), int(t%60)))\n",
    "    else:\n",
    "        results = []\n",
    "\n",
    "        # submit all computations\n",
    "        t0 = time()\n",
    "        for Rx in range(datacube.R_Nx):\n",
    "            for Ry in range(datacube.R_Ny):\n",
    "                if verbose:\n",
    "                    print_progress_bar(Rx*datacube.R_Ny+Ry+1, datacube.R_Nx*datacube.R_Ny,\n",
    "                                       prefix='Analyzing:', suffix='Complete', length=50)\n",
    "\n",
    "                DP = datacube.data4D[Rx,Ry,:,:]\n",
    "                results.append(\n",
    "                    view.apply(\n",
    "                        _find_Bragg_disks_single_DP_FK, \n",
    "                        DP, probe_kernel_FT, corrPower, sigma, edgeBoundary, \n",
    "                        minRelativeIntensity, minPeakSpacing, maxNumPeaks\n",
    "                ))\n",
    "\n",
    "        print(\"Number of computations: {}\".format(len(results)))\n",
    "        \n",
    "        # collect results\n",
    "        i = 0\n",
    "        for Rx in range(datacube.R_Nx):\n",
    "            for Ry in range(datacube.R_Ny):\n",
    "                peaks.get_pointlist(Rx, Ry).data = results[i].get().data.copy()\n",
    "                i += 1\n",
    "        t = time()-t0\n",
    "        print(\"Analyzed {} diffraction patterns in {}h {}m {}s\".format(datacube.R_N, int(t/3600),\n",
    "                                                                       int(t/60), int(t%60)))\n",
    "\n",
    "    return peaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ipp.Client(cluster_id=\"cori_20402773\")\n",
    "lbv = c.load_balanced_view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All DPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# Get peaks\n",
    "\n",
    "corrPower = 0.8\n",
    "sigma = 2\n",
    "edgeBoundary = 20\n",
    "maxNumPeaks = 70\n",
    "minPeakSpacing = 50\n",
    "minRelativeIntensity = 0.001\n",
    "verbose = False\n",
    "\n",
    "peaks = _find_Bragg_disks(dc, probe_kernel.data2D,\n",
    "                         corrPower=corrPower,\n",
    "                         sigma=sigma,\n",
    "                         edgeBoundary=edgeBoundary,\n",
    "                         minRelativeIntensity=minRelativeIntensity,\n",
    "                         minPeakSpacing=minPeakSpacing,\n",
    "                         maxNumPeaks=maxNumPeaks,\n",
    "                         verbose=verbose,\n",
    "                         view=lbv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show\n",
    "\n",
    "Rxs=(20,31,18)\n",
    "Rys=(25,31,10)\n",
    "power=0.3\n",
    "size_scale_factor = 500       # Set to zero to make all points the same size\n",
    "\n",
    "fig,((ax11,ax12),(ax21,ax22))=plt.subplots(2,2,figsize=(12,12))\n",
    "ax11.matshow(np.average(dc.data4D,axis=(2,3)))\n",
    "ax11.scatter(Rys,Rxs,color=('r','g','b'))\n",
    "ax12.matshow(dc.data4D[Rxs[0],Rys[0],:,:]**power)\n",
    "ax21.matshow(dc.data4D[Rxs[1],Rys[1],:,:]**power)\n",
    "ax22.matshow(dc.data4D[Rxs[2],Rys[2],:,:]**power)\n",
    "\n",
    "peaks0 = peaks.get_pointlist(Rxs[0],Rys[0])\n",
    "peaks1 = peaks.get_pointlist(Rxs[1],Rys[1])\n",
    "peaks2 = peaks.get_pointlist(Rxs[2],Rys[2])\n",
    "if size_scale_factor == 0:\n",
    "    ax12.scatter(peaks0.data['qy'],peaks0.data['qx'],color='r')\n",
    "    ax21.scatter(peaks1.data['qy'],peaks1.data['qx'],color='g')\n",
    "    ax22.scatter(peaks2.data['qy'],peaks2.data['qx'],color='b')\n",
    "else:\n",
    "    ax12.scatter(peaks0.data['qy'],peaks0.data['qx'],color='r',s=size_scale_factor*peaks0.data['intensity']/np.max(peaks0.data['intensity']))\n",
    "    ax21.scatter(peaks1.data['qy'],peaks1.data['qx'],color='g',s=size_scale_factor*peaks1.data['intensity']/np.max(peaks1.data['intensity']))\n",
    "    ax22.scatter(peaks2.data['qy'],peaks2.data['qx'],color='b',s=size_scale_factor*peaks2.data['intensity']/np.max(peaks2.data['intensity']))\n",
    "\n",
    "ax11.axis('off')\n",
    "ax12.axis('off')\n",
    "ax21.axis('off')\n",
    "ax22.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply post-detection thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove points based on new peak spacing or minimum relative intensity thresholds\n",
    "\n",
    "maxNumPeaks = 20\n",
    "minPeakSpacing = 50\n",
    "minRelativeIntensity = 0.01\n",
    "\n",
    "peaks_thresh = peaks.copy(name='Braggpeaks')  # Create a copy of the PointListArray to further threshold\n",
    "peaks_thresh = threshold_Braggpeaks(peaks_thresh,\n",
    "                                    minRelativeIntensity=minRelativeIntensity,\n",
    "                                    minPeakSpacing=minPeakSpacing,\n",
    "                                    maxNumPeaks=maxNumPeaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show\n",
    "\n",
    "Rxs=(20,31,18)\n",
    "Rys=(25,31,10)\n",
    "power=0.3\n",
    "size_scale_factor = 500       # Set to zero to make all points the same size\n",
    "\n",
    "fig,((ax11,ax12),(ax21,ax22))=plt.subplots(2,2,figsize=(12,12))\n",
    "ax11.matshow(np.average(dc.data4D,axis=(2,3)))\n",
    "ax11.scatter(Rys,Rxs,color=('r','g','b'))\n",
    "ax12.matshow(dc.data4D[Rxs[0],Rys[0],:,:]**power)\n",
    "ax21.matshow(dc.data4D[Rxs[1],Rys[1],:,:]**power)\n",
    "ax22.matshow(dc.data4D[Rxs[2],Rys[2],:,:]**power)\n",
    "\n",
    "peaks0 = peaks_thresh.get_pointlist(Rxs[0],Rys[0])\n",
    "peaks1 = peaks_thresh.get_pointlist(Rxs[1],Rys[1])\n",
    "peaks2 = peaks_thresh.get_pointlist(Rxs[2],Rys[2])\n",
    "if size_scale_factor == 0:\n",
    "    ax12.scatter(peaks0.data['qy'],peaks0.data['qx'],color='r')\n",
    "    ax21.scatter(peaks1.data['qy'],peaks1.data['qx'],color='g')\n",
    "    ax22.scatter(peaks2.data['qy'],peaks2.data['qx'],color='b')\n",
    "else:\n",
    "    ax12.scatter(peaks0.data['qy'],peaks0.data['qx'],color='r',s=size_scale_factor*peaks0.data['intensity']/np.max(peaks0.data['intensity']))\n",
    "    ax21.scatter(peaks1.data['qy'],peaks1.data['qx'],color='g',s=size_scale_factor*peaks1.data['intensity']/np.max(peaks1.data['intensity']))\n",
    "    ax22.scatter(peaks2.data['qy'],peaks2.data['qx'],color='b',s=size_scale_factor*peaks2.data['intensity']/np.max(peaks2.data['intensity']))\n",
    "\n",
    "ax11.axis('off')\n",
    "ax12.axis('off')\n",
    "ax21.axis('off')\n",
    "ax22.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py4dstem",
   "language": "python",
   "name": "py4dstem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
